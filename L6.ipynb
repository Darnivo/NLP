{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from random import shuffle\n",
    "\n",
    "from nltk import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import spacy\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "wnl = WordNetLemmatizer()\n",
    "stopw = stopwords.words(\"english\")\n",
    "\n",
    "dataset = pd.read_csv(\"./updated_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(document):\n",
    "    words = word_tokenize(document.lower())\n",
    "    words = [wnl.lemmatize(word) for word in words]\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    \n",
    "    return {word: True for word in words if word not in stopw and word.isalpha()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainmodel():\n",
    "    fset = [(preproc(txt),lbl) for txt,lbl in zip(dataset[\"text\"],dataset[\"label\"])]\n",
    "    shuffle(fset)\n",
    "    \n",
    "    split_idx = int(len(fset)*0.85)\n",
    "    trains,tests = fset[:split_idx],fset[split_idx:]\n",
    "    \n",
    "    clf = nltk.NaiveBayesClassifier.train(trains)\n",
    "    \n",
    "    acc = nltk.classify.accuracy(clf,tests)\n",
    "    print(f\"acc > {acc}\")\n",
    "    \n",
    "    clf.show_most_informative_features(5)\n",
    "    \n",
    "    file = open(\"model.pickle\",\"wb\")\n",
    "    pickle.dump(clf,file)\n",
    "    file.close()\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readmodel():\n",
    "    try:\n",
    "        file = open(\"model.pickle\",\"rb\")\n",
    "        clf = pickle.load(file)\n",
    "        file.close()\n",
    "        clf.show_most_informative_features(5)\n",
    "    except:\n",
    "        clf = trainmodel()\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writerev():\n",
    "    while True:\n",
    "        review = input(\"input >= 2 words\")\n",
    "        \n",
    "        if len(review.split()) >1:\n",
    "            return review\n",
    "        else:\n",
    "            print(\"too short\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(review,clf):\n",
    "    words = word_tokenize(review.lower())\n",
    "    words = FreqDist([word for word in words if word.isalpha and word not in string.punctuation])\n",
    "    \n",
    "    tags = pos_tag(words)\n",
    "    for i,word in enumerate(tags):\n",
    "        print(f\"{i+1}. {word[0]} > {word[1]}\")\n",
    "    print(\"\")\n",
    "    \n",
    "    for word in words:\n",
    "        synset = wordnet.synsets(word)\n",
    "        synos = []\n",
    "        antos = []\n",
    "        \n",
    "        for syns in synset:\n",
    "            for lemms in syns.lemmas():\n",
    "                synos.append(lemms.name())\n",
    "                for ants in lemms.antonyms():\n",
    "                    antos.append(ants.name())\n",
    "                    \n",
    "        synos = list(set(synos))\n",
    "        antos = list(set(antos))\n",
    "        \n",
    "        print(f\"{word} >\")\n",
    "        print(f\"Synonyms > {\", \".join(synos[:5]) if synos else \"none\"}\")\n",
    "        print(f\"Antonyms > {\", \".join(antos[:5]) if antos else \"none\"}\")\n",
    "        print(\"\")\n",
    "     \n",
    "    cleaned_rev = [word for word in word_tokenize(review) if word not in stopw and word not in string.punctuation]\n",
    "    cleaned_rev = [wnl.lemmatize(stemmer.stem(word)) for word in cleaned_rev]\n",
    "       \n",
    "    result = clf.classify(FreqDist(cleaned_rev))\n",
    "    print(f\"Review > {review} > {result}\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                 terribl = True           negati : positi =     10.8 : 1.0\n",
      "                 horribl = True           negati : positi =      9.5 : 1.0\n",
      "                 perfect = True           positi : negati =      8.4 : 1.0\n",
      "                  overpr = True           negati : positi =      8.2 : 1.0\n",
      "                    rude = True           negati : positi =      8.2 : 1.0\n",
      "1. i > NN\n",
      "2. am > VBP\n",
      "3. him > PRP\n",
      "\n",
      "i >\n",
      "Synonyms > i, single, iodin, unity, I\n",
      "Antonyms > none\n",
      "\n",
      "am >\n",
      "Synonyms > AM, constitute, cost, personify, be\n",
      "Antonyms > differ\n",
      "\n",
      "him >\n",
      "Synonyms > none\n",
      "Antonyms > none\n",
      "\n",
      "Review > i am him > negative\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classer = readmodel()\n",
    "# analyze(\"i am him\", classer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomm(review):\n",
    "    corpus = dataset[\"text\"]\n",
    "    target = dataset[\"restaurant\"]\n",
    "    \n",
    "    tfidf = TfidfVectorizer()\n",
    "    tfidf_mtr = tfidf.fit_transform(corpus)\n",
    "    query = tfidf.transform([review])\n",
    "    \n",
    "    simil = cosine_similarity(tfidf_mtr,query)\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'doc':corpus,\n",
    "        'target':target,\n",
    "        'simil':simil.flatten()\n",
    "    })\n",
    "    \n",
    "    recomms = df[df[\"simil\"]>0.15]\n",
    "    top_recomms = recomms.sort_values(by=\"simil\",ascending=False).head()\n",
    "    \n",
    "    \n",
    "    if recomms.empty:\n",
    "        print(\"No recomms\")\n",
    "    else:\n",
    "        for i, word in top_recomms.iterrows():\n",
    "            print(f\"{i}. {word[\"target\"]} > {word[\"simil\"]}\")\n",
    "\n",
    "# recomm(\"Contrary to other reviews, I have zero complaints about the service or the prices. I have been getting tire service here for the past 5 years now, and compared to my experience with places like Pep Boys, these guys are experienced and know what they're doing. \\nAlso, this is one place that I do not feel like I am being taken advantage of, just because of my gender. Other auto mechanics have been notorious for capitalizing on my ignorance of cars, and have sucked my bank account dry.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORG > microsoft\n",
      "LANGUAGE > english\n",
      "GPE > jakarta\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "ner_lab = nlp.get_pipe(\"ner\").labels\n",
    "# print(ner_lab)\n",
    "\n",
    "def ner(review):\n",
    "    categorized_ents = defaultdict(set)\n",
    "    doc = nlp(review)\n",
    "    \n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in [\"GPE\", \"LANGUAGE\", \"ORG\"]:\n",
    "            categorized_ents[ent.label_].add(ent.text)\n",
    "    \n",
    "    for cat,ent in categorized_ents.items():\n",
    "        print(f\"{cat} > {\", \".join(sorted(ent))}\")\n",
    "        \n",
    "ner(\"He works at the microsoft english branch of jakarta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                 terribl = True           negati : positi =     10.8 : 1.0\n",
      "                 horribl = True           negati : positi =      9.5 : 1.0\n",
      "                 perfect = True           positi : negati =      8.4 : 1.0\n",
      "                  overpr = True           negati : positi =      8.2 : 1.0\n",
      "                    rude = True           negati : positi =      8.2 : 1.0\n",
      "Menu blablabla\n",
      "review : no reviews\n",
      "sent : no sent\n",
      "input >>( 2 )\n",
      "!!review empty\n",
      "\n",
      "Menu blablabla\n",
      "review : no reviews\n",
      "sent : no sent\n",
      "input >>( 1 )\n",
      "\n",
      "Menu blablabla\n",
      "review : the service of the english employees of Microsoft at Jakarta is terrible\n",
      "sent : no sent\n",
      "input >>( 2 )\n",
      "1. the > DT\n",
      "2. of > IN\n",
      "3. service > NN\n",
      "4. english > JJ\n",
      "5. employees > NNS\n",
      "6. microsoft > VBP\n",
      "7. at > IN\n",
      "8. jakarta > NN\n",
      "9. is > VBZ\n",
      "10. terrible > JJ\n",
      "\n",
      "the >\n",
      "Synonyms > none\n",
      "Antonyms > none\n",
      "\n",
      "of >\n",
      "Synonyms > none\n",
      "Antonyms > none\n",
      "\n",
      "service >\n",
      "Synonyms > Robert_William_Service, serving, service_of_process, religious_service, table_service\n",
      "Antonyms > disservice\n",
      "\n",
      "english >\n",
      "Synonyms > English_language, English_people, English, side\n",
      "Antonyms > none\n",
      "\n",
      "employees >\n",
      "Synonyms > employee\n",
      "Antonyms > employer\n",
      "\n",
      "microsoft >\n",
      "Synonyms > none\n",
      "Antonyms > none\n",
      "\n",
      "at >\n",
      "Synonyms > atomic_number_85, At, astatine, at\n",
      "Antonyms > none\n",
      "\n",
      "jakarta >\n",
      "Synonyms > Djakarta, Jakarta, capital_of_Indonesia\n",
      "Antonyms > none\n",
      "\n",
      "is >\n",
      "Synonyms > constitute, cost, personify, be, make_up\n",
      "Antonyms > differ\n",
      "\n",
      "terrible >\n",
      "Synonyms > dire, frightful, terrible, atrocious, abominable\n",
      "Antonyms > none\n",
      "\n",
      "Review > the service of the english employees of Microsoft at Jakarta is terrible > negative\n",
      "\n",
      "Menu blablabla\n",
      "review : the service of the english employees of Microsoft at Jakarta is terrible\n",
      "sent : negative\n",
      "input >>( 3 )\n",
      "453. Restaurant D > 0.1641322355355483\n",
      "259. Restaurant E > 0.157755136920167\n",
      "466. Restaurant B > 0.15073137063301822\n",
      "\n",
      "Menu blablabla\n",
      "review : the service of the english employees of Microsoft at Jakarta is terrible\n",
      "sent : negative\n",
      "input >>( 4 )\n",
      "ORG > Microsoft\n",
      "GPE > Jakarta\n",
      "\n",
      "Menu blablabla\n",
      "review : the service of the english employees of Microsoft at Jakarta is terrible\n",
      "sent : negative\n",
      "input >>( 5 )\n",
      "!!exiting\n"
     ]
    }
   ],
   "source": [
    "clf = readmodel()\n",
    "review = \"\"\n",
    "sent = \"\"\n",
    "\n",
    "while True:\n",
    "    print(\"Menu blablabla\")\n",
    "    print(\"review :\",review if review else \"no reviews\")\n",
    "    print(\"sent :\",sent if sent else \"no sent\")\n",
    "    \n",
    "    print(\"input >>\",end=\"\",flush=True)\n",
    "    choice = input(\"enter input\")\n",
    "    print(f\"( {choice} )\")\n",
    "    \n",
    "    if choice == '1':\n",
    "        review = writerev()\n",
    "    elif choice == '2':\n",
    "        if review:\n",
    "            sent = analyze(review,clf)\n",
    "        else:\n",
    "            print(\"!!review empty\")\n",
    "    elif choice == '3':\n",
    "        if review:\n",
    "            recomm(review)\n",
    "        else:\n",
    "            print(\"!!review empty\")\n",
    "    elif choice == '4':\n",
    "        if review:\n",
    "            ner(review)\n",
    "        else:\n",
    "            print(\"!!review empty\")\n",
    "    elif choice == '5':\n",
    "        print(\"!!exiting\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"!!input out of range\")\n",
    "        \n",
    "    print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
