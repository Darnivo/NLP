{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from random import shuffle\n",
    "\n",
    "from nltk import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import PorterStemmer,WordNetLemmatizer\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import spacy\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "wnl = WordNetLemmatizer()\n",
    "stopw = stopwords.words(\"english\")\n",
    "\n",
    "dataset = pd.read_csv(\"./updated_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(document):\n",
    "    words = word_tokenize(document.lower())\n",
    "    \n",
    "    words = [wnl.lemmatize(word) for word in words]\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    \n",
    "    return {word:True for word in words if word not in stopw and word.isalpha()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainmodel():\n",
    "    fset = [(preproc(txt),label) for txt,label in zip(dataset[\"text\"],dataset[\"label\"])]\n",
    "    shuffle(fset)\n",
    "    \n",
    "    split_idx = int(len(fset)*0.85)\n",
    "    trains,tests = fset[:split_idx],fset[split_idx:]\n",
    "    \n",
    "    clf = nltk.NaiveBayesClassifier.train(trains)\n",
    "    \n",
    "    acc = nltk.classify.accuracy(clf,tests)\n",
    "    print(f\"acc > {acc}\")\n",
    "    \n",
    "    clf.show_most_informative_features(5)\n",
    "    \n",
    "    \n",
    "    file = open(\"model.pickle\",\"wb\")\n",
    "    pickle.dump(clf,file)\n",
    "    file.close()\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readmodel():\n",
    "    try:\n",
    "        file = open(\"model.pickle\",\"rb\")\n",
    "        clf = pickle.load(file)\n",
    "        clf.show_most_informative_features(5)\n",
    "        file.close()\n",
    "    except:\n",
    "        clf = trainmodel()\n",
    "        \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writerev():\n",
    "    while True:\n",
    "        review = input(\"Input must be >=2 words\")\n",
    "        \n",
    "        if len(review.split())>1:\n",
    "            return review\n",
    "        else:\n",
    "            print(\"Too short\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                 terribl = True           negati : positi =     13.8 : 1.0\n",
      "                 perfect = True           positi : negati =     13.5 : 1.0\n",
      "                 horribl = True           negati : positi =      9.8 : 1.0\n",
      "                   anyon = True           negati : positi =      9.1 : 1.0\n",
      "                  receiv = True           negati : positi =      8.4 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier = readmodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. owen JJ\n",
      "2. loves VBZ\n",
      "3. little JJ\n",
      "4. children NNS\n",
      "\n",
      "word >  owen\n",
      "Sir_Richard_Owen, Robert_Owen, Owen\n",
      "no ants\n",
      "===\n",
      "word >  loves\n",
      "bang, have_a_go_at_it, passion, lovemaking, make_out, love, do_it, sleep_with, making_love, sleep_together, have_it_off, get_it_on, get_laid, have_intercourse, dearest, enjoy, honey, eff, know, erotic_love, fuck, bonk, have_sex, bed, be_intimate, hump, have_it_away, roll_in_the_hay, jazz, sexual_love, lie_with, dear, make_love, beloved, screw, love_life\n",
      "hate\n",
      "===\n",
      "word >  little\n",
      "lilliputian, little, small, trivial, fiddling, petty, footling, niggling, short, picayune, minuscule, piffling, piddling, slight\n",
      "big, large, much, tall\n",
      "===\n",
      "word >  children\n",
      "youngster, tiddler, minor, child, shaver, tike, baby, nipper, fry, small_fry, kid, nestling, tyke\n",
      "parent\n",
      "===\n",
      "\n",
      "owen loves little children > positive\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def analyze(review:str,clf):\n",
    "    words = word_tokenize(review.lower())\n",
    "    words = [word for word in words if word not in string.punctuation and word.isalpha()]\n",
    "    \n",
    "    tags = pos_tag(words)\n",
    "    for i,word in enumerate(tags):\n",
    "        print(f\"{i+1}. {word[0]} {word[1]}\")\n",
    "    print(\"\")    \n",
    "    \n",
    "    for word in words:\n",
    "        print(\"word > \",word)\n",
    "        synos = []\n",
    "        antos = []\n",
    "        \n",
    "        synset = wordnet.synsets(word)\n",
    "        \n",
    "        for syns in synset:\n",
    "            for lemm in syns.lemmas():\n",
    "                synos.append(lemm.name())\n",
    "                for anto in lemm.antonyms():\n",
    "                    antos.append(anto.name())\n",
    "        \n",
    "        \n",
    "        #use to remove dupes         \n",
    "        synos = list(set(synos))\n",
    "        antos = list(set(antos))\n",
    "                    \n",
    "        print(\", \".join(synos) if synos else \"no syns\")\n",
    "        print(\", \".join(antos) if antos else \"no ants\")\n",
    "        print(\"===\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"\")\n",
    "    \n",
    "    cleaned_rev = [word for word in word_tokenize(review) if word not in string.punctuation and word not in stopw]\n",
    "    cleaned_rev = [wnl.lemmatize(stemmer.stem(word)) for word in cleaned_rev]\n",
    "    \n",
    "    result = clf.classify(FreqDist(cleaned_rev))\n",
    "    print(f\"{review} > {result}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# analyze(\"owen loves little children\", classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 > Restaurant C 0.4629912053109412\n",
      "387 > Restaurant C 0.16381587462932606\n",
      "195 > Restaurant A 0.15969550308016198\n",
      "170 > Restaurant A 0.15228221911813097\n",
      "305 > Restaurant A 0.15161707817897763\n"
     ]
    }
   ],
   "source": [
    "def recomm(review):\n",
    "    corpus = dataset[\"text\"]\n",
    "    target = dataset[\"restaurant\"]\n",
    "    \n",
    "    tfidf = TfidfVectorizer()\n",
    "    tfidf_mtr = tfidf.fit_transform(corpus)\n",
    "    query = tfidf.transform([review])\n",
    "    \n",
    "    simil = cosine_similarity(tfidf_mtr,query)\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'doc':corpus,\n",
    "        'target':target,\n",
    "        'simil':simil.flatten()\n",
    "    })\n",
    "    \n",
    "    recomms = df[df[\"simil\"]>0.15]\n",
    "    \n",
    "    top_recomms = recomms.sort_values(by='simil',ascending=False).head(10)\n",
    "    \n",
    "    # top_recomms = top_recomms.reset_index(drop=True)\n",
    "    \n",
    "    return top_recomms[['target','simil']]\n",
    "\n",
    "\n",
    "recommends = recomm(\"My orders have come out bad pretty much every time I have ordered from here.\")\n",
    "\n",
    "if recommends.empty:\n",
    "    print(\"no recomms\")\n",
    "else:\n",
    "    for idx, row in recommends.iterrows():\n",
    "        print(f\"{idx} > {row['target']} {row['simil']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPE > Indonesia\n",
      "ORG > Apple inc, microsoft\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "ner_label = nlp.get_pipe(\"ner\").labels\n",
    "\n",
    "# print(ner_label)\n",
    "\n",
    "def ner(review):\n",
    "    categorized_data = defaultdict(set)\n",
    "    doc = nlp(review)\n",
    "    \n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in [\"GPE\",\"ORG\",\"LANGUAGE\"]:\n",
    "            categorized_data[ent.label_].add(ent.text)\n",
    "            \n",
    "    for cat,ent in categorized_data.items():\n",
    "        print(f\"{cat} > {\", \".join(sorted(ent))}\")\n",
    "        \n",
    "ner(\"Indonesia seeks to ban microsoft in favor of Apple inc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                 terribl = True           negati : positi =     13.8 : 1.0\n",
      "                 perfect = True           positi : negati =     13.5 : 1.0\n",
      "                 horribl = True           negati : positi =      9.8 : 1.0\n",
      "                   anyon = True           negati : positi =      9.1 : 1.0\n",
      "                  receiv = True           negati : positi =      8.4 : 1.0\n",
      "Menu, select command\n",
      "rev > no review\n",
      "sent > no sent\n",
      ">>"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "try again\n",
      "Menu, select command\n",
      "rev > this is perfect\n",
      "sent > no sent\n",
      ">>2\n",
      "1. this DT\n",
      "2. is VBZ\n",
      "3. perfect JJ\n",
      "\n",
      "word >  this\n",
      "no syns\n",
      "no ants\n",
      "===\n",
      "word >  is\n",
      "cost, exist, follow, live, comprise, embody, represent, constitute, make_up, equal, personify, be\n",
      "differ\n",
      "===\n",
      "word >  perfect\n",
      "complete, unadulterated, perfective_tense, staring, everlasting, arrant, hone, pure, consummate, perfective, perfect, sodding, stark, thoroughgoing, double-dyed, utter, gross, perfect_tense\n",
      "imperfect\n",
      "===\n",
      "\n",
      "this is perfect > positive\n",
      "Updated sentiment: positive\n",
      "Menu, select command\n",
      "rev > this is perfect\n",
      "sent > positive\n",
      ">>5\n"
     ]
    }
   ],
   "source": [
    "classifier = readmodel()\n",
    "review =\"\"\n",
    "sent = \"\"\n",
    "\n",
    "while True:\n",
    "    print(\"Menu, select command\")\n",
    "    print(f\"rev > {review if review else \"no review\"}\")\n",
    "    print(f\"sent > {sent if sent else \"no sent\"}\")\n",
    "    \n",
    "    print(\">>\",flush=True, end = \"\")\n",
    "    choice = input(\"enter 1-5\")\n",
    "    print(choice)\n",
    "    \n",
    "    \n",
    "    if choice == '1':\n",
    "        review = writerev()\n",
    "    if choice == '2':\n",
    "        if review:\n",
    "            sent = analyze(review, classifier)\n",
    "            print(f\"Updated sentiment: {sent}\")  # Debugging line\n",
    "        else:\n",
    "            print(\"no rev!\")\n",
    "    elif choice == '3':\n",
    "        pass\n",
    "    elif choice == '4':\n",
    "        pass\n",
    "    elif choice == '5':\n",
    "        break\n",
    "    else:\n",
    "        print(\"try again\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
