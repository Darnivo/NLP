{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5base 5recom #2recom #2ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pickle\n",
    "import string\n",
    "import pandas as pd\n",
    "from random import shuffle\n",
    "\n",
    "from nltk import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import spacy\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "wnl = WordNetLemmatizer()\n",
    "stopw = stopwords.words(\"english\")\n",
    "\n",
    "dataset = pd.read_csv(\"./updated_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(document):\n",
    "    words = word_tokenize(document.lower())\n",
    "    \n",
    "    words = [wnl.lemmatize(word) for word in words]\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    \n",
    "    return {word:True for word in words if word not in stopw and word.isalpha()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainmodel():\n",
    "    fset = [(preproc(txt),label) for txt,label in zip(dataset[\"text\"],dataset[\"label\"])]\n",
    "    shuffle(fset)\n",
    "    \n",
    "    split = int(len(fset)*0.85)\n",
    "    trains,tests = fset[:split],fset[split:]\n",
    "    \n",
    "    clf = nltk.NaiveBayesClassifier.train(trains)\n",
    "    \n",
    "    acc = nltk.classify.accuracy(clf,tests)\n",
    "    print(acc)\n",
    "    \n",
    "    clf.show_most_informative_features(5)\n",
    "    \n",
    "    file = open(\"model.pickle\",\"wb\")\n",
    "    pickle.dump(clf,file)\n",
    "    file.close()\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readmodel():\n",
    "    try:\n",
    "        file = open(\"model.pickle\",\"rb\")\n",
    "        clf = pickle.load(file)\n",
    "        clf.show_most_informative_features(5)\n",
    "        file.close()\n",
    "    except:\n",
    "        clf = trainmodel()\n",
    "        \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writerev():\n",
    "    while True:\n",
    "        review = input(\"move than 2 words\")\n",
    "        \n",
    "        if len(review.split())>1:\n",
    "            return review\n",
    "        else:\n",
    "            print (\"too short\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8072289156626506\n",
      "Most Informative Features\n",
      "                 terribl = True           negati : positi =     12.8 : 1.0\n",
      "                    rude = True           negati : positi =     11.4 : 1.0\n",
      "                    okay = True           negati : positi =     10.0 : 1.0\n",
      "                 fantast = True           positi : negati =      9.3 : 1.0\n",
      "                    card = True           negati : positi =      8.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier = readmodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. you > PRP\n",
      "2. are > VBP\n",
      "3. terrible > JJ\n",
      "you are terrible > negative\n"
     ]
    }
   ],
   "source": [
    "def analyze(review:str,clf):\n",
    "    words = word_tokenize(review.lower())\n",
    "    words = FreqDist([word for word in words if word.isalpha() and word not in string.punctuation])\n",
    "    \n",
    "    tags = pos_tag(words)\n",
    "    for i,word in enumerate(tags):\n",
    "        print(f\"{i+1}. {word[0]} > {word[1]}\")\n",
    "    \n",
    "    clean_rev = [word for word in word_tokenize(review) if word not in stopw and word not in string.punctuation]\n",
    "    clean_rev = [wnl.lemmatize(stemmer.stem(word)) for word in clean_rev]\n",
    "    \n",
    "    result = clf.classify(FreqDist(clean_rev))\n",
    "\n",
    "    print(f\"{review} > {result}\")\n",
    "\n",
    "# analyze(\"you are terrible\", classifier)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264 > Restaurant D > 0.28072732862084204\n",
      "1 > Restaurant A > 0.19631737999176635\n",
      "168 > Restaurant C > 0.1897028741200557\n",
      "19 > Restaurant D > 0.18668342947623362\n"
     ]
    }
   ],
   "source": [
    "def recomm(review):\n",
    "    corpus = dataset[\"text\"]\n",
    "    target = dataset[\"restaurant\"]\n",
    "    \n",
    "    tfidf = TfidfVectorizer()\n",
    "    tfidf_mtr = tfidf.fit_transform(corpus)\n",
    "    query = tfidf.transform([review])\n",
    "    \n",
    "    simil = cosine_similarity(tfidf_mtr,query)\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'doc':corpus,\n",
    "        'target':target,\n",
    "        'simil':simil.flatten()\n",
    "    })\n",
    "    \n",
    "    recomms = df[df['simil']>0.15]\n",
    "    \n",
    "    top_recomms = recomms.sort_values(by='simil',ascending=False).head()\n",
    "    \n",
    "    return top_recomms[['target','simil']]\n",
    "\n",
    "\n",
    "# x = recomm(\"I have zero complaints\")\n",
    "\n",
    "# if x.empty:\n",
    "#     print(\"empty\")\n",
    "# else:\n",
    "#     for idx, row in x.iterrows():\n",
    "#                 print(f\"{idx+1} > {row['target']} > {row['simil']}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('CARDINAL', 'DATE', 'EVENT', 'FAC', 'GPE', 'LANGUAGE', 'LAW', 'LOC', 'MONEY', 'NORP', 'ORDINAL', 'ORG', 'PERCENT', 'PERSON', 'PRODUCT', 'QUANTITY', 'TIME', 'WORK_OF_ART')\n",
      "LANGUAGE > English\n",
      "ORG > the Apple Inc HQ\n",
      "GPE > Jakarta\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "ner_label = nlp.get_pipe(\"ner\").labels\n",
    "\n",
    "print(ner_label)\n",
    "\n",
    "def ner(review):\n",
    "    categorized_ents = defaultdict(set)\n",
    "    doc = nlp(review)\n",
    "    \n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in [\"GPE\",\"LANGUAGE\",\"ORG\"]:\n",
    "            categorized_ents[ent.label_].add(ent.text)\n",
    "    \n",
    "    for cat,ent in categorized_ents.items():\n",
    "        print(f\"{cat} > {\", \".join(sorted(ent))}\")\n",
    "\n",
    "ner(\"He is fluent in English like most workers in the Apple Inc HQ of Jakarta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n",
      "good\n",
      ">>>> evil\n",
      "goodness\n",
      ">>>> evilness\n",
      "good\n",
      ">>>> bad\n",
      "goodness\n",
      ">>>> badness\n",
      "commodity\n",
      "trade_good\n",
      "good\n",
      "good\n",
      ">>>> bad\n",
      "full\n",
      "good\n",
      "good\n",
      ">>>> evil\n",
      "estimable\n",
      "good\n",
      "honorable\n",
      "respectable\n",
      "beneficial\n",
      "good\n",
      "good\n",
      "good\n",
      "just\n",
      "upright\n",
      "adept\n",
      "expert\n",
      "good\n",
      "practiced\n",
      "proficient\n",
      "skillful\n",
      "skilful\n",
      "good\n",
      "dear\n",
      "good\n",
      "near\n",
      "dependable\n",
      "good\n",
      "safe\n",
      "secure\n",
      "good\n",
      "right\n",
      "ripe\n",
      "good\n",
      "well\n",
      "effective\n",
      "good\n",
      "in_effect\n",
      "in_force\n",
      "good\n",
      "good\n",
      "serious\n",
      "good\n",
      "sound\n",
      "good\n",
      "salutary\n",
      "good\n",
      "honest\n",
      "good\n",
      "undecomposed\n",
      "unspoiled\n",
      "unspoilt\n",
      "good\n",
      "well\n",
      ">>>> ill\n",
      "good\n",
      "thoroughly\n",
      "soundly\n",
      "good\n"
     ]
    }
   ],
   "source": [
    "synsets = wordnet.synsets(\"good\")\n",
    "\n",
    "for synset in synsets:\n",
    "    for lemma in synset.lemmas():\n",
    "        print(lemma.name())\n",
    "        for antonym in lemma.antonyms():\n",
    "            print(\">>>>\",antonym.name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty\n",
      "not empty\n",
      "1, 1\n"
     ]
    }
   ],
   "source": [
    "xyy = []\n",
    "\n",
    "if not xyy:\n",
    "    print(\"empty\")\n",
    "else:\n",
    "    print(\"not empty\")\n",
    "    \n",
    "xyy.append(1)\n",
    "xyy.append(1)\n",
    "xyy.append(1)\n",
    "\n",
    "if not xyy:\n",
    "    print(\"empty\")\n",
    "else:\n",
    "    print(\"not empty\")\n",
    "    \n",
    "print(\", \".join(map(str, xyy[:2])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
